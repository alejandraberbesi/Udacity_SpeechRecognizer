# Speech Recognition with Neural Networks (2022)

## Introduction

This project centers on building an end-to-end Automatic Speech Recognition (ASR) pipeline using deep neural networks. The pipeline processes raw audio input to generate a predicted text transcription of the spoken language.

## Project Context

The project explores fundamental ASR components:

* Acoustic Feature Extraction: Converting raw audio into common representations like Spectrograms or Mel-Frequency Cepstral Coefficients (MFCCs).

* Acoustic Modeling with Deep Neural Networks: Designing and training various neural network architectures (including RNNs, CNN+RNNs, Bidirectional RNNs, and deeper models) to map audio features to a probability distribution over possible transcriptions. The models are trained using the CTC loss function.

* Prediction: Deciphering the acoustic model's output into a final text transcription.

## Contribution Note

Please Note: The code, text, images, and other files in this repository are NOT my intellectual property. They belong to the Udacity Artificial Intelligence Nanodegree Program. My contributions were focused on the 'IMPLEMENTATION' sections within the vui_notebook.ipynb notebook and in developing specific neural network architectures within sample_models.py.
